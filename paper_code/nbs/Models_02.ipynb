{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce5900-d60f-428d-9872-e1a6adf11849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6da465-de94-4c42-a842-f59070be48da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.functional.classification import (\n",
    "    binary_accuracy,\n",
    "    binary_auroc,\n",
    "    binary_f1_score,\n",
    "    binary_matthews_corrcoef,\n",
    "    binary_precision,\n",
    "    binary_recall,\n",
    ")\n",
    "from torchmetrics.utilities.data import to_onehot\n",
    "from torchvision.models import (\n",
    "    ResNet50_Weights,\n",
    "    resnet50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d139c8e-3bfb-430e-b05e-bcbb88ef276b",
   "metadata": {
    "id": "GNLyB_gFfQLb",
    "tags": []
   },
   "source": [
    "## MixUp Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c147e7-8768-43f7-9e86-cea15d0d6902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=0, verbose=False):\n",
    "    \"\"\"Mixes up the input data and targets according to a beta distribution.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): The input data tensor.\n",
    "        y (Tensor): The target tensor.\n",
    "        alpha (float, optional): The alpha parameter for the beta distribution. Default is 0.\n",
    "        verbose (bool, optional): A flag to enable visualization and logging. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor, Tensor, float]: A tuple containing the mixed input data,\n",
    "        first set of mixed targets, second set of mixed targets, and lambda value for mixing.\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    index = index.type_as(x).long()\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * torch.index_select(x, 0, index)\n",
    "    y_a, y_b = y, torch.index_select(y, 0, index)\n",
    "\n",
    "    if verbose:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        print(y_a[0], y_b[0], lam)\n",
    "        plt.imshow(x[0, 0].cpu(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(x[index[0], 0].cpu(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "        plt.imshow(mixed_x[0, 0].cpu(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Computes the mixup loss based on the original and shuffled labels.\n",
    "\n",
    "    Args:\n",
    "        criterion (function): The loss function, e.g., cross-entropy loss.\n",
    "        pred (Tensor): The predictions from the network.\n",
    "        y_a (Tensor): The original labels.\n",
    "        y_b (Tensor): The labels of the shuffled batch.\n",
    "        lam (float): The lambda value used for mixing up.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The computed mixup loss.\n",
    "    \"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "def mixup_metric(metric, preds, y_a, y_b, lam):\n",
    "    \"\"\"Computes the mixup-adjusted metric based on the original and shuffled labels.\n",
    "\n",
    "    Args:\n",
    "        metric (function): The metric function to use, e.g., accuracy.\n",
    "        preds (Tensor): The predictions from the network.\n",
    "        y_a (Tensor): The original labels.\n",
    "        y_b (Tensor): The labels of the shuffled batch.\n",
    "        lam (float): The lambda value used for mixing up.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed mixup-adjusted metric value.\n",
    "    \"\"\"\n",
    "\n",
    "    return lam * metric(preds, y_a) + (1 - lam) * metric(preds, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68291360-c496-4a2a-841f-d6dd75d0fbca",
   "metadata": {},
   "source": [
    "## LightningModule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e353b5fa-4ba4-4ee2-861f-a63bd3e3304b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763ec001-91ae-44fb-a1c8-645fccb20b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ResNet50 with Integration of MixUp and Discriminative Learning rates\n",
    "class ResNetTransferLearningDiscriminativeLR(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        only_fc,\n",
    "        max_lr,\n",
    "        wd,\n",
    "        lr_mult,\n",
    "        alpha,\n",
    "        first_dropout,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.only_fc = only_fc\n",
    "        self.max_learning_rate = max_lr\n",
    "        self.weight_decay = wd\n",
    "        self.lr_mult = lr_mult\n",
    "        self.first_dropout = first_dropout\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.loss = torch.nn.CrossEntropyLoss(label_smoothing=0.01)\n",
    "        self.metric = binary_accuracy\n",
    "\n",
    "        backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        num_input_channel = 1\n",
    "        layer = backbone.conv1\n",
    "        new_layer = nn.Conv2d(\n",
    "            in_channels=num_input_channel,\n",
    "            out_channels=layer.out_channels,\n",
    "            kernel_size=layer.kernel_size,\n",
    "            stride=layer.stride,\n",
    "            padding=layer.padding,\n",
    "            bias=layer.bias,\n",
    "        )\n",
    "        new_layer.weight = nn.Parameter(layer.weight.sum(dim=1, keepdim=True))\n",
    "\n",
    "        backbone.conv1 = new_layer\n",
    "\n",
    "        if self.only_fc is True:\n",
    "            for param in backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        backbone.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(self.first_dropout),\n",
    "            nn.Linear(1024, 2),\n",
    "        )\n",
    "\n",
    "        self.model = backbone\n",
    "\n",
    "        layer_names = []\n",
    "        # Populate layer names from the model's named parameters\n",
    "        for _idx, (name, _param) in enumerate(self.model.named_parameters()):\n",
    "            layer_names.append(name)\n",
    "        layer_names.reverse()\n",
    "        lr = self.max_learning_rate\n",
    "        lr_mult = self.lr_mult\n",
    "\n",
    "        parameters = []\n",
    "        prev_group_name = layer_names[0].split(\".\")[0]\n",
    "\n",
    "        # Loop through layer names to update learning rates and collect parameters\n",
    "        for _idx, name in enumerate(layer_names):\n",
    "            cur_group_name = name.split(\".\")[0]  # Extract current group name\n",
    "\n",
    "            # Update learning rate if group name changes\n",
    "            if cur_group_name != prev_group_name:\n",
    "                lr *= lr_mult\n",
    "            prev_group_name = cur_group_name  # Update previous group name for next iteration\n",
    "\n",
    "            # print(f'{idx}: lr = {lr:.6f}, {name}')\n",
    "\n",
    "            # Store parameters and their associated learning rates\n",
    "            parameters += [\n",
    "                {\n",
    "                    \"params\": [\n",
    "                        p for n, p in self.model.named_parameters() if n == name and p.requires_grad\n",
    "                    ],\n",
    "                    \"lr\": lr,\n",
    "                }\n",
    "            ]\n",
    "            self.param = parameters\n",
    "            lrs = [i[\"lr\"] for i in self.param]\n",
    "            self.lrs = lrs\n",
    "            self.lrs_base = [i / 8 for i in self.lrs]\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.param,\n",
    "            lr=0,  # gets overridden by self.params\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.lrs,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "        lr_scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "            \"frequency\": 1,\n",
    "            \"monitor\": \"val_acc\",\n",
    "            \"strict\": True,\n",
    "            \"name\": None,\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_config}\n",
    "\n",
    "    def training_step(self, batch_data, batch_idx):\n",
    "        x, y = batch_data[\"image\"], batch_data[\"label\"]\n",
    "        x, y_a, y_b, lam = mixup_data(x, y, self.alpha, verbose=False)\n",
    "        x, y_a, y_b = map(Variable, (x, y_a, y_b))\n",
    "        logits = self.forward(x)\n",
    "        loss = mixup_criterion(self.loss, logits, y_a, y_b, lam)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = mixup_metric(self.metric, preds, y_a, y_b, lam)\n",
    "        self.log(\"train_loss\", loss, sync_dist=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, sync_dist=True, prog_bar=True)\n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": y}\n",
    "\n",
    "    def validation_step(self, batch_data, batch_idx):\n",
    "        val_images, val_labels_dense = batch_data[\"image\"], batch_data[\"label\"]\n",
    "        preds = self.forward(val_images)\n",
    "        val_labels = to_onehot(val_labels_dense, num_classes=num_class)\n",
    "        val_loss = torch.nn.functional.cross_entropy(preds, val_labels_dense, label_smoothing=0.01)\n",
    "\n",
    "        val_acc = binary_accuracy(preds, val_labels)\n",
    "        val_F1 = binary_f1_score(preds, val_labels)\n",
    "        val_precision = binary_precision(preds, val_labels)\n",
    "        val_recall = binary_recall(preds, val_labels)\n",
    "        val_MCC = binary_matthews_corrcoef(preds, val_labels)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_precision\": val_precision,\n",
    "                \"val_recall\": val_recall,\n",
    "                \"val_F1\": val_F1,\n",
    "                \"val_MCC\": val_MCC,\n",
    "                \"val_loss\": val_loss,\n",
    "            },\n",
    "            sync_dist=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_preds\": preds,\n",
    "            \"val_targets\": val_labels,\n",
    "            \"val_MCC\": val_MCC,\n",
    "        }\n",
    "\n",
    "    def validation_step_end(self, outputs):\n",
    "        val_acc = binary_accuracy(outputs[\"val_preds\"], outputs[\"val_targets\"])\n",
    "        val_F1 = binary_f1_score(outputs[\"val_preds\"], outputs[\"val_targets\"])\n",
    "        val_precision = binary_precision(outputs[\"val_preds\"], outputs[\"val_targets\"])\n",
    "        val_recall = binary_recall(outputs[\"val_preds\"], outputs[\"val_targets\"])\n",
    "        val_MCC = binary_matthews_corrcoef(outputs[\"val_preds\"], outputs[\"val_targets\"])\n",
    "        auroc = binary_auroc(\n",
    "            torch.Tensor(outputs[\"val_preds\"].type(torch.float32)),\n",
    "            outputs[\"val_targets\"],\n",
    "        )\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"val_acc\": val_acc,\n",
    "                \"val_precision\": val_precision,\n",
    "                \"val_recall\": val_recall,\n",
    "                \"val_F1\": val_F1,\n",
    "                \"val_MCC\": val_MCC,\n",
    "                \"val_auroc\": auroc,\n",
    "            },\n",
    "            sync_dist=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "        return {\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_F1\": val_F1,\n",
    "            \"val_MCC\": val_MCC,\n",
    "            \"val_auroc\": auroc,\n",
    "        }\n",
    "\n",
    "    def predict_step(self, batch_data, batch_idx):\n",
    "        softmax = nn.Softmax()\n",
    "        inputs, targets_dense = batch_data[\"image\"], batch_data[\"label\"]\n",
    "        preds = self.forward(inputs)\n",
    "        preds = torch.tensor(softmax(preds))\n",
    "        targets = to_onehot(targets_dense, num_classes=num_class)\n",
    "        return {\"preds\": preds, \"targets\": targets}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
